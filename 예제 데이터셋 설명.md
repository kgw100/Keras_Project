#### *들어가기전에

각 코드에 대한 것과 자세한 것은 코드단에서 주석처리해 내용을 설명하였으며, md파일에서는 데이터 셋에 관한 내용만을 서술하였습니다.



### 3.4 IMDB 데이터 셋 

인터넷 영화 데이터 베이스로부터 가져온 양극단의 리뷰 5만 개로 이루어진 데이터셋 , 이 데이터셋은 훈련 데이터 2만 5000개와 테스트 데이터 2만 5000개로 나뉘어 있고 각각 50%는 부정, 50%는 긍정 리뷰로 구성되어 있습니다. ( 이 데이터셋은 스탠포드 대학의 앤드류 마스가 수집한 데이터 셋)

###### *훈련 데이터와 테스트 데이터로 구분하는 이유 => 훈련 데이터에서  머신 러닝이 잘 작동한다고 해서 처음 만난 데이터에서도 잘 작동한다는 것을 보장할 수 없습니다.

이 데이터는 전처리되어 있어 각 리뷰가 숫자 시퀀스로 변환되어 있고,  각 숫자는 사전에 있는 고유한 단어를 나타냅니다.



#### *과정

데이터 준비 (숫자 리스트를 신경망에 주입할 수 없기 때문에 린서를 텐서로 바꿈 ) -> 신경망 모델 생성 ->훈련 검증-> 예측 



## 3.5 로이터 데이터셋

 1986년에  로이터에서 공개한 짧은 뉴스 기사와 토픽의 집합, 금융 관련 카테고리

로토 뉴스를 46개의 상호 배타적인 토픽으로 분류하는 신경망을 만드는 과정,

클래스가 많기 때문에 이 문제는 다중 분류의 예입니다. 각 데이터 포인트가 정확히 하나의 범주로 분류되기 때문에 좀 더 정확히 말하면 단일 레이블 다중 분류문제입니다.  3.4의 IMDB와 마차간지로 미리 전체 데이터셋의 단어를 고유한 정수 인덱스로 바꾼 후에 훈련 데이터와 테스트 데이터로 나누어 놓습니다. 



### 3.6 보스턴 주택 가격 데이터셋

1970년 중반 보스턴 외곽 지역의 범죄율, 지방세율 등의 데이터가 주어졌을 때 주택 가격의 중간 값을 예측할 것입니다.  이는 개별적인 레이블 대신에 연속적인 값을 예측하는 __회귀__입니다.  ex) 기상 데이터가 주어졌을 때 내일 기온을 예측하거나, 소프트웨어 명세가 주어졌을 때 소프트웨어 프로젝트가 완료될 시간을 예측하는 것  



이 데이터셋은 데이터 포인트가 506개로 비교적 앞 예제와 비교했을 떄 개수가 적고 404개는 훈련 샘플, 102는 테스트 샘플로 나누어 져있습니다. 



